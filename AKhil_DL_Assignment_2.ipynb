{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Assignment_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankojubhanuprakash/Machine_learning_practice/blob/main/AKhil_DL_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ],
      "metadata": {
        "id": "1Jq76C-QQbd0"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_format(n):\n",
        "  input_seq = []\n",
        "  for i in range(6):\n",
        "    bit = 1 if n&(1<<(5-i)) != 0 else 0\n",
        "    input_seq.append(bit)\n",
        "  return input_seq"
      ],
      "metadata": {
        "id": "5Wz13UH-i72v"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parity_sequence(data):\n",
        "  list_parity_sequence = []\n",
        "  count = 0\n",
        "  for i in data:\n",
        "    j = 0\n",
        "    if int(i) == 0:\n",
        "      count+=1\n",
        "    if count%2 ==0:\n",
        "      j = 1\n",
        "    list_parity_sequence.append(j)\n",
        "  return list_parity_sequence"
      ],
      "metadata": {
        "id": "yMO2tFlTjBnN"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "nY_rhbsHEFpv"
      },
      "outputs": [],
      "source": [
        "list_of_binary_values = []\n",
        "list_of_parity_sequence = []\n",
        "binary_value = []\n",
        "for i in range(0,2**6):\n",
        "  binary_value = binary_format(i)\n",
        "  list_of_binary_values.append(binary_value)\n",
        "  parity_sequence_data = parity_sequence(binary_value)\n",
        "  list_of_parity_sequence.append(parity_sequence_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.array(list_of_binary_values)\n",
        "output=np.array(list_of_parity_sequence).reshape(64,6,1).astype(np.float32)"
      ],
      "metadata": {
        "id": "aJqj21bAQfoD"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=x.reshape(64,6,1).astype(np.float32)"
      ],
      "metadata": {
        "id": "W2xZE1JncYpL"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.SimpleRNN(1, return_sequences=True,activation='sigmoid',input_shape=(6,1)))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n"
      ],
      "metadata": {
        "id": "pqJiVWttQmp9"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-EaRH55U6Dy",
        "outputId": "dd169bfc-69c6-4bd3-903a-c73986ec8e0f"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_19 (SimpleRNN)   (None, 6, 1)              3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x,output, test_size=0.33, random_state=42,)"
      ],
      "metadata": {
        "id": "Yjtl-5Efg622"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=100, batch_size=1, validation_data=(X_test, y_test),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQKI6vordgup",
        "outputId": "c3cd21f8-f0ed-43eb-8824-68d7a50055b4"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "42/42 [==============================] - 1s 7ms/step - loss: 0.2610 - val_loss: 0.2453\n",
            "Epoch 2/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2599 - val_loss: 0.2453\n",
            "Epoch 3/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2589 - val_loss: 0.2453\n",
            "Epoch 4/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2581 - val_loss: 0.2453\n",
            "Epoch 5/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2573 - val_loss: 0.2454\n",
            "Epoch 6/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2566 - val_loss: 0.2455\n",
            "Epoch 7/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2557 - val_loss: 0.2455\n",
            "Epoch 8/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2551 - val_loss: 0.2456\n",
            "Epoch 9/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2547 - val_loss: 0.2458\n",
            "Epoch 10/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2539 - val_loss: 0.2459\n",
            "Epoch 11/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2535 - val_loss: 0.2460\n",
            "Epoch 12/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2530 - val_loss: 0.2461\n",
            "Epoch 13/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2527 - val_loss: 0.2463\n",
            "Epoch 14/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2522 - val_loss: 0.2464\n",
            "Epoch 15/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2519 - val_loss: 0.2465\n",
            "Epoch 16/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2516 - val_loss: 0.2466\n",
            "Epoch 17/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2513 - val_loss: 0.2466\n",
            "Epoch 18/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2509 - val_loss: 0.2468\n",
            "Epoch 19/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2507 - val_loss: 0.2469\n",
            "Epoch 20/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2504 - val_loss: 0.2471\n",
            "Epoch 21/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2502 - val_loss: 0.2471\n",
            "Epoch 22/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2500 - val_loss: 0.2473\n",
            "Epoch 23/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2498 - val_loss: 0.2472\n",
            "Epoch 24/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2497 - val_loss: 0.2474\n",
            "Epoch 25/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2494 - val_loss: 0.2475\n",
            "Epoch 26/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2492 - val_loss: 0.2475\n",
            "Epoch 27/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2491 - val_loss: 0.2476\n",
            "Epoch 28/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2491 - val_loss: 0.2477\n",
            "Epoch 29/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2489 - val_loss: 0.2479\n",
            "Epoch 30/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2488 - val_loss: 0.2478\n",
            "Epoch 31/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2486 - val_loss: 0.2479\n",
            "Epoch 32/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2485 - val_loss: 0.2479\n",
            "Epoch 33/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2484 - val_loss: 0.2478\n",
            "Epoch 34/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2483 - val_loss: 0.2478\n",
            "Epoch 35/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2482 - val_loss: 0.2479\n",
            "Epoch 36/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2481 - val_loss: 0.2479\n",
            "Epoch 37/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2481 - val_loss: 0.2481\n",
            "Epoch 38/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2480 - val_loss: 0.2481\n",
            "Epoch 39/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2478 - val_loss: 0.2480\n",
            "Epoch 40/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2478 - val_loss: 0.2480\n",
            "Epoch 41/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2477 - val_loss: 0.2479\n",
            "Epoch 42/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2476 - val_loss: 0.2481\n",
            "Epoch 43/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2476 - val_loss: 0.2480\n",
            "Epoch 44/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2475 - val_loss: 0.2481\n",
            "Epoch 45/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2474 - val_loss: 0.2481\n",
            "Epoch 46/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2474 - val_loss: 0.2481\n",
            "Epoch 47/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2474 - val_loss: 0.2482\n",
            "Epoch 48/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2473 - val_loss: 0.2479\n",
            "Epoch 49/100\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2472 - val_loss: 0.2480\n",
            "Epoch 50/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2471 - val_loss: 0.2478\n",
            "Epoch 51/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2471 - val_loss: 0.2479\n",
            "Epoch 52/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2470 - val_loss: 0.2479\n",
            "Epoch 53/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2471 - val_loss: 0.2479\n",
            "Epoch 54/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2469 - val_loss: 0.2479\n",
            "Epoch 55/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2469 - val_loss: 0.2478\n",
            "Epoch 56/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2469 - val_loss: 0.2477\n",
            "Epoch 57/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2468 - val_loss: 0.2478\n",
            "Epoch 58/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2467 - val_loss: 0.2477\n",
            "Epoch 59/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2467 - val_loss: 0.2476\n",
            "Epoch 60/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2467 - val_loss: 0.2478\n",
            "Epoch 61/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2468 - val_loss: 0.2474\n",
            "Epoch 62/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2466 - val_loss: 0.2475\n",
            "Epoch 63/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2465 - val_loss: 0.2475\n",
            "Epoch 64/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2465 - val_loss: 0.2475\n",
            "Epoch 65/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2464 - val_loss: 0.2475\n",
            "Epoch 66/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2464 - val_loss: 0.2474\n",
            "Epoch 67/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2464 - val_loss: 0.2475\n",
            "Epoch 68/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2464 - val_loss: 0.2472\n",
            "Epoch 69/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2465 - val_loss: 0.2475\n",
            "Epoch 70/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2463 - val_loss: 0.2472\n",
            "Epoch 71/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2463 - val_loss: 0.2473\n",
            "Epoch 72/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2463 - val_loss: 0.2470\n",
            "Epoch 73/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2461 - val_loss: 0.2471\n",
            "Epoch 74/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2461 - val_loss: 0.2470\n",
            "Epoch 75/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2462 - val_loss: 0.2472\n",
            "Epoch 76/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2460 - val_loss: 0.2470\n",
            "Epoch 77/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2460 - val_loss: 0.2469\n",
            "Epoch 78/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2460 - val_loss: 0.2470\n",
            "Epoch 79/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2460 - val_loss: 0.2470\n",
            "Epoch 80/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2460 - val_loss: 0.2467\n",
            "Epoch 81/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2459 - val_loss: 0.2467\n",
            "Epoch 82/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2459 - val_loss: 0.2467\n",
            "Epoch 83/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2459 - val_loss: 0.2468\n",
            "Epoch 84/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2459 - val_loss: 0.2466\n",
            "Epoch 85/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2458 - val_loss: 0.2467\n",
            "Epoch 86/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2458 - val_loss: 0.2468\n",
            "Epoch 87/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2458 - val_loss: 0.2466\n",
            "Epoch 88/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2458 - val_loss: 0.2464\n",
            "Epoch 89/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2457 - val_loss: 0.2466\n",
            "Epoch 90/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2457 - val_loss: 0.2465\n",
            "Epoch 91/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2457 - val_loss: 0.2464\n",
            "Epoch 92/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2457 - val_loss: 0.2464\n",
            "Epoch 93/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2456 - val_loss: 0.2463\n",
            "Epoch 94/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2456 - val_loss: 0.2464\n",
            "Epoch 95/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2456 - val_loss: 0.2463\n",
            "Epoch 96/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2455 - val_loss: 0.2463\n",
            "Epoch 97/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2456 - val_loss: 0.2463\n",
            "Epoch 98/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2456 - val_loss: 0.2463\n",
            "Epoch 99/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.2455 - val_loss: 0.2463\n",
            "Epoch 100/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2456 - val_loss: 0.2460\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb7ca86fe50>"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = keras.Sequential()\n",
        "model2.add(layers.SimpleRNN(1, return_sequences=True,activation='sigmoid',input_shape=(6,1)))\n",
        "model2.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True), optimizer='adam',metrics=[keras.metrics.SparseCategoricalAccuracy()])"
      ],
      "metadata": {
        "id": "SKlcY_y6YQDx"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ERaXGRoljS7v"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(X_train, y_train, epochs=100, batch_size=1, validation_data=(X_test, y_test),\n",
        ")"
      ],
      "metadata": {
        "outputId": "ff7f5e9b-843b-49a0-b5c4-dee6ec633e50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSPrjZkJjS70"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "42/42 [==============================] - 1s 8ms/step - loss: 0.7610 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.7213 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 2/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7588 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.7198 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 3/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7567 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.7183 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 4/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7545 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.7169 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 5/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7524 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.7155 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 6/100\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.7503 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.7140 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 7/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7483 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.7125 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 8/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7461 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.7114 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 9/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7442 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.7102 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 10/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7423 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.7089 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 11/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7405 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.7078 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 12/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7386 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.7068 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 13/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7369 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.7058 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 14/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7353 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.7049 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 15/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7337 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.7040 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 16/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7323 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.7031 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 17/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7307 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.7024 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 18/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7294 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.7018 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 19/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7282 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.7011 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 20/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7269 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.7005 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 21/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7257 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6999 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 22/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7246 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6994 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 23/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7236 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6989 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 24/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7225 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6984 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 25/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7217 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6979 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 26/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7207 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6975 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 27/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7199 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6972 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 28/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7190 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6968 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 29/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7183 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6965 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 30/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7175 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6962 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 31/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7169 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6959 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 32/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7161 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6956 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 33/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7155 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6954 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 34/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7149 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6951 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 35/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7143 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6949 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 36/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7138 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6947 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 37/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7133 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6945 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 38/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7128 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6943 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 39/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7123 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6941 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 40/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7118 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6940 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 41/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7114 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6938 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 42/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7109 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6937 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 43/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7106 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6935 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 44/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7102 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6934 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 45/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7098 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6933 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 46/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7094 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6931 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 47/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7091 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6930 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 48/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7087 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6929 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 49/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7084 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6928 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 50/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7081 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6927 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 51/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7078 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6926 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 52/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7075 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6925 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 53/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7072 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6924 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 54/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7069 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6924 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 55/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7067 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6923 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 56/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7064 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6922 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 57/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7062 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6921 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 58/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7060 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6921 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 59/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7057 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6920 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 60/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7055 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6919 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 61/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7053 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6919 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 62/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7051 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6918 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 63/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7048 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6918 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 64/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7047 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6917 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 65/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7045 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6917 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 66/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7043 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6916 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 67/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7041 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6916 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 68/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7039 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6915 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 69/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7037 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6915 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 70/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7036 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6915 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 71/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7034 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 72/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7032 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 73/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7031 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6913 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 74/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7029 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6913 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 75/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7028 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6913 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 76/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7027 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6912 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 77/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7025 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6912 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 78/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7024 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6912 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 79/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7022 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6911 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 80/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7021 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6911 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 81/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7020 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6911 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 82/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7018 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6910 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 83/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7017 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6910 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 84/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7016 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6910 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 85/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7015 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6910 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 86/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7014 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6909 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 87/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7012 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6909 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 88/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7011 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6909 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 89/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7010 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6909 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 90/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7009 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6909 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 91/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7008 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6908 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 92/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7007 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6908 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 93/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7006 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6908 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 94/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7005 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6908 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 95/100\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.7004 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6907 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 96/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7003 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6907 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 97/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7002 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6907 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 98/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7001 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6907 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 99/100\n",
            "42/42 [==============================] - 0s 3ms/step - loss: 0.7001 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6907 - val_sparse_categorical_accuracy: 0.4697\n",
            "Epoch 100/100\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.7000 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.6906 - val_sparse_categorical_accuracy: 0.4697\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb7ca632e50>"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s3PkiGVCJneT"
      }
    }
  ]
}